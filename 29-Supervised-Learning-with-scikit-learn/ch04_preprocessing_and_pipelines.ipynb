{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83930df-8652-4cfe-84b9-1145b082453d",
   "metadata": {},
   "source": [
    "# Chapter #4: Preprocessing and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7872ce3-6c74-4384-a0f7-0df4d3163e3e",
   "metadata": {},
   "source": [
    "## 1. Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a70f9-547b-410b-b17d-d78bec26a5a2",
   "metadata": {},
   "source": [
    "**scikit-learn requirements**\n",
    "> - Recall that **scikit-learn requires numeric data, with no missing values**.\n",
    "> - All the data that we have used so far has been in this format.\n",
    "> - However, with **real-world data**, this will rarely be the case, and instead **we need to preprocess our data before we can build models**.\n",
    "\n",
    "**Dealing with categorical features**\n",
    "> - Say we have a dataset containing **categorical features**, such as color.\n",
    "> - As these are not numeric, **scikit-learn will not accept them** and we need to convert them into **numeric features**.\n",
    "> - We achieve this by **splitting the feature into multiple binary features called dummy variables**, one for each category.\n",
    "> - **`0`** means the observation was **not that category**, while **`1`** means **it was**.\n",
    "\n",
    "**Dummy variables**\n",
    "> - Say we are working with a music dataset that has a genre feature with 10 values such as Electronic, Hip-Hop, and Rock.\n",
    "> - We create **binary features** for each genre.\n",
    "> - As each song has one genre, **each row will have a `1` in one of the 10 columns** and `0` in the rest.\n",
    "> - If a song is not any of the first nine genres, **then implicitly, it is a rock song**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img01.png\">\n",
    "\n",
    "**Dummy variables**\n",
    "> - That means **we only need nine features, so we can delete the Rock column**.\n",
    "> - If we do not do this, **we are duplicating information, which might be an issue for some models**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img02.png\">\n",
    "\n",
    "**Dealing with categorical features in Python**\n",
    "> - To create **dummy variables** we can use:\n",
    ">> - **scikit-learn's** `OneHotEncoder()`,\n",
    ">> - **pandas'** `get_dummies()`.\n",
    "> - We will use **`get_dummies()`**.\n",
    "\n",
    "**Music dataset**\n",
    "> - We will be working with a **music dataset** in this chapter, for both **classification** and **regression** problems.\n",
    "> - Initially, we will build a **regression model** using all features in the dataset to **predict song `popularity`**.\n",
    "> - There is one categorical feature, **`genre`**, with **ten possible values**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img03.png\">\n",
    "\n",
    "**EDA w/ categorical feature**\n",
    "> - This box plot shows how **`popularity` varies by `genre`**.\n",
    "> - Let's encode this feature using **dummy variables**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img04.png\">\n",
    "\n",
    "**Encoding dummy variables**\n",
    "> - We **import** pandas, **read** in the DataFrame, and **call** `pd.get_dummies()`, **passing** the categorical column.\n",
    "> - As we only need to keep 9 out of our 10 binary features, we can **set** the `drop_first` argument to `True`.\n",
    "> - Printing the first five rows, we see **pandas creates 9 new binary features**.\n",
    "> - The first song is Jazz, and the second is Rap, indicated by a `1` in the respective columns.\n",
    "> - To bring these binary features back into our original DataFrame we can **use** `pd.concat()`, **passing** a list containing the `music_df` DataFrame and our `music_dummies` DataFrame, and setting `axis` equal to `1`.\n",
    "> - Lastly, we can **remove** the original `genre` column using `.drop()`, **passing(()) the column, and setting `axis` equal to `1`.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img05.png\">\n",
    "\n",
    "**Encoding dummy variables**\n",
    "> - If the DataFrame only has one categorical feature, we can **pass** the entire DataFrame, thus skipping the step of combining variables.\n",
    "> - If we **don't specify a column**, the new DataFrame's binary columns will have the original feature name **prefixed**, so they will start with genre-underscore - as shown here.\n",
    "> - Notice the original genre column is **automatically dropped**.\n",
    "> - Once we have dummy variables, we can **fit** models as before.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img07.png\">\n",
    "\n",
    "**Linear regression with dummy variables**\n",
    "> - Using the `music_dummies` DataFrame, the process for creating **training** and **test sets** remains unchanged.\n",
    "> - To perform **cross-validation** we then **create** a `KFold()` object, **instantiate** a linear regression model, and **call** `cross_val_score()`.\n",
    "> - We **set** scoring equal to `neg_mean_squared_error`, which **returns the negative MSE**.\n",
    "> - This is because scikit-learn's cross-validation metrics presume a **higher score is better**, so **MSE** is changed to **negative MSE** to counteract this.\n",
    "> - We can **calculate** the training RMSE by **taking the square root and converting to positive**, achieved by **calling** `numpy.square-root()` and **passing** our scores with a **minus sign** in front.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img08.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d79409-bdc0-48f8-8375-67365a10e340",
   "metadata": {},
   "source": [
    "### 1.1. Creating dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68d607-f9bc-4ea1-82c1-53162cc60941",
   "metadata": {},
   "source": [
    "Being able to **include categorical features in the model building process** can enhance performance as they may add information that contributes to prediction accuracy.\n",
    "\n",
    "The `music_df` dataset has been preloaded for you, and its shape is printed. Also, `pandas` has been imported as `pd`.\n",
    "\n",
    "Now you will create a new DataFrame containing the original columns of `music_df` plus dummy variables from the `\"genre\"` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d21d33-105f-48fb-8c21-9367e3f29978",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c387215-ef24-4c95-92aa-1777bf12f6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.823</td>\n",
       "      <td>236533.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>102.619000</td>\n",
       "      <td>0.649</td>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154373.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>173.915000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.669</td>\n",
       "      <td>217778.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.522</td>\n",
       "      <td>245960.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.595</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229400.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>96.056000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy   \n",
       "0        41.0        0.6440         0.823     236533.0   0.814  \\\n",
       "1        62.0        0.0855         0.686     154373.0   0.670   \n",
       "2        42.0        0.2390         0.669     217778.0   0.736   \n",
       "3        64.0        0.0125         0.522     245960.0   0.923   \n",
       "4        60.0        0.1210         0.780     229400.0   0.467   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence   \n",
       "0          0.687000    0.1170    -5.611       0.1770  102.619000    0.649  \\\n",
       "1          0.000000    0.1200    -7.626       0.2250  173.915000    0.636   \n",
       "2          0.000169    0.5980    -3.223       0.0602  145.061000    0.494   \n",
       "3          0.017000    0.0854    -4.560       0.0539  120.406497    0.595   \n",
       "4          0.000134    0.3140    -6.645       0.2530   96.056000    0.312   \n",
       "\n",
       "        genre  \n",
       "0        Jazz  \n",
       "1         Rap  \n",
       "2  Electronic  \n",
       "3        Rock  \n",
       "4         Rap  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv(\"./datasets/ch04_01_01_creating_dummy_variables.csv\").drop(columns=\"Unnamed: 0\")\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41263729-bfc7-4acd-b95e-62b60a5968f5",
   "metadata": {},
   "source": [
    "- Use a relevant function, passing the entire `music_df` DataFrame, to create `music_dummies`, dropping the first binary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39d3a13-042c-4378-9301-9ccb35f02c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_anime</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_hip-hop</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_rap</th>\n",
       "      <th>genre_rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.823</td>\n",
       "      <td>236533.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>102.619000</td>\n",
       "      <td>0.649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154373.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>173.915000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.669</td>\n",
       "      <td>217778.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.522</td>\n",
       "      <td>245960.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.595</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229400.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>96.056000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy   \n",
       "0        41.0        0.6440         0.823     236533.0   0.814  \\\n",
       "1        62.0        0.0855         0.686     154373.0   0.670   \n",
       "2        42.0        0.2390         0.669     217778.0   0.736   \n",
       "3        64.0        0.0125         0.522     245960.0   0.923   \n",
       "4        60.0        0.1210         0.780     229400.0   0.467   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence   \n",
       "0          0.687000    0.1170    -5.611       0.1770  102.619000    0.649  \\\n",
       "1          0.000000    0.1200    -7.626       0.2250  173.915000    0.636   \n",
       "2          0.000169    0.5980    -3.223       0.0602  145.061000    0.494   \n",
       "3          0.017000    0.0854    -4.560       0.0539  120.406497    0.595   \n",
       "4          0.000134    0.3140    -6.645       0.2530   96.056000    0.312   \n",
       "\n",
       "   genre_anime  genre_blues  genre_classical  genre_country  genre_electronic   \n",
       "0        False        False            False          False             False  \\\n",
       "1        False        False            False          False             False   \n",
       "2        False        False            False          False              True   \n",
       "3        False        False            False          False             False   \n",
       "4        False        False            False          False             False   \n",
       "\n",
       "   genre_hip-hop  genre_jazz  genre_rap  genre_rock  \n",
       "0          False        True      False       False  \n",
       "1          False       False       True       False  \n",
       "2          False       False      False       False  \n",
       "3          False       False      False        True  \n",
       "4          False       False       True       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dummies = pd.get_dummies(music_df, drop_first=True).rename(columns=lambda x: x.lower())\n",
    "music_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc37b8-5083-4bd1-8e7a-2cb372561159",
   "metadata": {},
   "source": [
    "- Print the shape of `music_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21447c2b-e06a-4e36-9a16-b754e1e40a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a78d1-ff21-4deb-af56-795876ddf030",
   "metadata": {},
   "source": [
    "### 1.2. Regression with categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9f2aa-74d0-4a6f-8b55-97c9ae8b232c",
   "metadata": {},
   "source": [
    "Now you have created `music_dummies`, containing binary features for each song's genre, it's time to **build a ridge regression model to predict song popularity**.\n",
    "\n",
    "`music_dummies` has been preloaded for you, along with `Ridge`, `cross_val_score`, `numpy` as `np`, and a `KFold()` object stored as `kf`.\n",
    "\n",
    "The model will be evaluated by calculating the average RMSE, but first, you will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value â€”`\"popularity\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cd5e5-3d90-45d3-9447-f6156b3b6ec2",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8dce75-7cb3-47f9-b37f-c9368b285bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_anime</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_hip-hop</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_rap</th>\n",
       "      <th>genre_rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.823</td>\n",
       "      <td>236533.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>102.619000</td>\n",
       "      <td>0.649</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154373.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>173.915000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.669</td>\n",
       "      <td>217778.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.522</td>\n",
       "      <td>245960.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.595</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229400.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>96.056000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy   \n",
       "0        41.0        0.6440         0.823     236533.0   0.814  \\\n",
       "1        62.0        0.0855         0.686     154373.0   0.670   \n",
       "2        42.0        0.2390         0.669     217778.0   0.736   \n",
       "3        64.0        0.0125         0.522     245960.0   0.923   \n",
       "4        60.0        0.1210         0.780     229400.0   0.467   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence   \n",
       "0          0.687000    0.1170    -5.611       0.1770  102.619000    0.649  \\\n",
       "1          0.000000    0.1200    -7.626       0.2250  173.915000    0.636   \n",
       "2          0.000169    0.5980    -3.223       0.0602  145.061000    0.494   \n",
       "3          0.017000    0.0854    -4.560       0.0539  120.406497    0.595   \n",
       "4          0.000134    0.3140    -6.645       0.2530   96.056000    0.312   \n",
       "\n",
       "   genre_anime  genre_blues  genre_classical  genre_country  genre_electronic   \n",
       "0        False        False            False          False             False  \\\n",
       "1        False        False            False          False             False   \n",
       "2        False        False            False          False              True   \n",
       "3        False        False            False          False             False   \n",
       "4        False        False            False          False             False   \n",
       "\n",
       "   genre_hip-hop  genre_jazz  genre_rap  genre_rock  \n",
       "0          False        True      False       False  \n",
       "1          False       False       True       False  \n",
       "2          False       False      False       False  \n",
       "3          False       False      False        True  \n",
       "4          False       False       True       False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d2119d-253a-404d-9084-e48666fd257c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14d96eb-9682-4f81-9a31-ebb3f55f5b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac37ee-6736-4be5-b2aa-ee00cf563327",
   "metadata": {},
   "source": [
    "- Create `X`, containing all features in `music_dummies`, and `y`, consisting of the `\"popularity\"` column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7743e28a-3ce5-41df-a843-3f3bcfa47d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = music_dummies.drop(columns=\"popularity\").values\n",
    "y = music_df[\"popularity\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04879a-d739-408c-9d68-99809a80dd5a",
   "metadata": {},
   "source": [
    "- Instantiate a `ridge` regression model, setting `alpha` equal to `0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8b6dcc-15df-411a-a356-e27e5dc1f0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8f60c-fa65-4efb-8a56-633fb5dafbcb",
   "metadata": {},
   "source": [
    "- Perform cross-validation on `X` and `y` using the `ridge` model, setting `cv` equal to `kf`, and using negative mean squared error as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d3a07e-02b3-44c4-9b96-4c0e0eeffd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c016e31-baec-4b11-9489-ea3dcdecd971",
   "metadata": {},
   "source": [
    "- Print the RMSE values by converting negative `scores` to positive and taking the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c5ce5f-9a70-4e03-b594-b06b48d18af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313d62b7-6e30-47f5-811b-143bb38b1429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 8.24\n",
      "Standard deviation of the target array: 14.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average RMSE: {np.mean(rmse):.2f}\")\n",
    "print(f\"Standard deviation of the target array: {np.std(y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645d912b-4049-464b-bcb6-81457f929969",
   "metadata": {},
   "source": [
    "## 2. Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c0d8a-2c8a-4af7-8294-1de151d4ae67",
   "metadata": {},
   "source": [
    "**Missing data**\n",
    "> - When there is **no value** for a feature in a particular row, we call it **missing** data.\n",
    "> - This can happen because **there was no observation or the data might be corrupt**.\n",
    "> - Whatever the reason, **we need to deal with it**.\n",
    "\n",
    "**Music dataset**\n",
    "> - Previously we worked with a **modified music dataset**.\n",
    "> - Now let's inspect the **original version**, which contains one thousand rows.\n",
    "> - We do this by **chaining `pandas`' `.isna()` with `.sum()` and `.sort_values()` methods**.\n",
    "> - Each feature is missing **between `8` and `200`** values!\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img01.png\">\n",
    "\n",
    "**Dropping missing data**\n",
    "> - A common approach is to **remove missing observations accounting for less than 5% of all data**.\n",
    "> - To do this, we **use `pandas`' `.dropna()` method**, passing a list of **columns with less than 5% missing values** to the subset argument.\n",
    "> - If there are missing values in our subset column, **the entire row is removed**.\n",
    "> - **Rechecking** the DataFrame, we see **fewer missing values**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img02.png\">\n",
    "\n",
    "**Imputing values**\n",
    "> - Another option is to **impute missing data**.\n",
    "> - This means **making an educated guess as to what the missing values could be**:\n",
    ">> - We can impute the **mean** of all non-missing entries for a given feature,\n",
    ">> - We can also use other values like the **median**,\n",
    ">> - For **categorical** values we commonly impute the **most frequent value**.\n",
    "> - **Note we must split our data before imputing to avoid leaking test set information to our model, a concept known as data leakage.**\n",
    "\n",
    "**Imputation with scikit-learn**\n",
    "> - Here is a **workflow** for imputation to predict song popularity:\n",
    ">> - We **import** `SimpleImputer` from `sklearn.impute`,\n",
    ">> - As we will use **different imputation methods** for **categorical** and **numeric** features, we first **split** them, **storing** as `X_cat` and `X_num` respectively, along with our target array as `y`,\n",
    ">> - We **create** categorical training and test sets,\n",
    ">> - We **repeat** this for the numeric features,\n",
    ">> - By **using the same value for the `random_state` argument**, the target arrays' values remain **unchanged**,\n",
    ">> - To impute missing categorical values we **instantiate** a `SimpleImputer`, **setting** strategy as most frequent,\n",
    ">> - By default, `SimpleImputer` expects `numpy.nan` to represent **missing values**,\n",
    ">> - Now we **call** `.fit_transform()` to impute the training categorical features' missing values!\n",
    ">> - **For the test categorical features, we call `.transform()`.**\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img03.png\">\n",
    "\n",
    "**Imputation with scikit-learn**\n",
    "> - For our **numeric** data, we **instantiate** another imputer.\n",
    "> - By default, it fills values with the **mean**.\n",
    "> - **We fit and transform the training features, and transform the test features.**\n",
    "> - We then **combine** our training data using `numpy.append()`, **passing** our two arrays, and set `axis` equal to `1`.\n",
    "> - We **repeat** this for our test data.\n",
    "> - Due to their ability to **transform** our data, imputers are known as **transformers**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img04.png\">\n",
    "\n",
    "**Imputing within a pipeline**\n",
    "> - We can also impute using a **pipeline**, which is an **object used to run a series of transformations and build a model in a single workflow**.\n",
    "> - To do this, we **import** `Pipeline` from `sklearn.pipeline`.\n",
    "> - Here we perform **binary classification** to predict whether a song is rock or another genre.\n",
    "> - We **drop** missing values accounting for less than 5% of our data.\n",
    "> - We **convert** values in the genre column, which will be the target, to a `1` if Rock, else `0`, using `numpy.where()`.\n",
    "> - We then create `X` and `y`.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img05.png\">\n",
    "\n",
    "**Imputing within a pipeline**\n",
    "> - To build a pipeline we **construct** a list of steps containing **tuples with the step names specified as strings, and instantiate the transformer or model**. \n",
    "> - We **pass** this list when **instantiating** a Pipeline.\n",
    "> - We then **split** our data, and **fit** the pipeline to the training data, as with any other model.\n",
    "> - Finally, we **compute** accuracy.\n",
    "> - **Note that, in a pipeline, each step but the last must be a transformer.**\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f2345-bd5c-4ee4-89c0-f49bb1fce6f8",
   "metadata": {},
   "source": [
    "### 2.1. Dropping missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df068f-ad90-449f-b83a-c7ad9ea6e46a",
   "metadata": {},
   "source": [
    "Over the next three exercises, you are going to **tidy the `music_df` dataset**. You will **create a pipeline to impute missing values** and build a KNN classifier model, then use it to predict whether a song is of the `\"Rock\"` genre.\n",
    "\n",
    "In this exercise specifically, you will drop missing values accounting for less than 5% of the dataset, and convert the `\"genre\"` column into a binary feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da72a36-467a-40ee-8bce-49b63e01cd72",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da8615a-35be-4eb4-a92a-6bbfd86ca9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.69400</td>\n",
       "      <td>0.610</td>\n",
       "      <td>217400.0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>-7.325</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>137.838000</td>\n",
       "      <td>0.352</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.73900</td>\n",
       "      <td>0.565</td>\n",
       "      <td>260467.0</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-9.309</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>75.537000</td>\n",
       "      <td>0.229</td>\n",
       "      <td>Anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.433</td>\n",
       "      <td>262867.0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>-3.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.358000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.359</td>\n",
       "      <td>563893.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>-8.323</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>89.259000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30100</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.496</td>\n",
       "      <td>Anime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy   \n",
       "0        64.0       0.69400         0.610     217400.0   0.590  \\\n",
       "1        31.0       0.73900         0.565     260467.0   0.393   \n",
       "2        57.0       0.00879         0.433     262867.0   0.815   \n",
       "3        63.0       0.01050         0.359     563893.0   0.762   \n",
       "4         NaN       0.30100         0.511          NaN   0.699   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence   \n",
       "0          0.000002    0.1500    -7.325       0.0362  137.838000    0.352  \\\n",
       "1          0.000845    0.1430    -9.309       0.0244   75.537000    0.229   \n",
       "2          0.000000    0.1380    -3.658          NaN  125.358000    0.461   \n",
       "3          0.281000    0.3680    -8.323       0.0320   89.259000    0.167   \n",
       "4               NaN    0.0884       NaN       0.0370  120.406497    0.496   \n",
       "\n",
       "   genre  \n",
       "0    NaN  \n",
       "1  Anime  \n",
       "2   Rock  \n",
       "3   Rock  \n",
       "4  Anime  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv(\"./datasets/ch04_02_01_dropping_missing_data.csv\").drop(columns=\"Unnamed: 0\")\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1032a2-e730-4b62-830a-555a511d806c",
   "metadata": {},
   "source": [
    "- Print the number of missing values for each column in the `music_df` dataset, sorted in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c70bb669-fc7c-462c-81fe-e00800cbcfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre                 8\n",
       "popularity           31\n",
       "loudness             44\n",
       "liveness             46\n",
       "tempo                46\n",
       "speechiness          59\n",
       "duration_ms          91\n",
       "instrumentalness     91\n",
       "danceability        143\n",
       "valence             143\n",
       "acousticness        200\n",
       "energy              200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03f60f-a10c-4765-8dbf-8f8aa6b6e142",
   "metadata": {},
   "source": [
    "- Remove values for all columns with `50` or fewer missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7985ffcf-679a-4a91-8d73-468929a45029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_to_dopna = ['genre', 'popularity', 'loudness', 'liveness', 'tempo']\n",
    "music_df.dropna(subset=cols_to_dopna, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc4af1-f73c-447a-a266-00d828019651",
   "metadata": {},
   "source": [
    "- Convert `music_df[\"genre\"]` to values of `1` if the row contains `\"Rock\"`, otherwise change the value to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11a74fc-74ce-43cc-af1f-2463aad97f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ceaed41-2787-4511-b09b-c9a1d4d71591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity            0\n",
      "liveness              0\n",
      "loudness              0\n",
      "tempo                 0\n",
      "genre                 0\n",
      "duration_ms          29\n",
      "instrumentalness     29\n",
      "speechiness          53\n",
      "danceability        127\n",
      "valence             127\n",
      "acousticness        178\n",
      "energy              178\n",
      "dtype: int64\n",
      "\n",
      "Shape of the music_df: (892, 12)\n"
     ]
    }
   ],
   "source": [
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"\\nShape of the music_df: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f1cff-6792-42c1-8a57-26e79c390e5a",
   "metadata": {},
   "source": [
    "### 2.2. Pipeline for song genre prediction: I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167bd823-472a-468f-a044-37303baaf6ae",
   "metadata": {},
   "source": [
    "Now it's time to** build a pipeline**. It will contain steps to impute missing values using the mean for each feature and build a KNN model for the classification of song genre.\n",
    "\n",
    "The modified `music_df` dataset that you created in the previous exercise has been preloaded for you, along with `KNeighborsClassifier` and `train_test_split`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a2cee-ce4c-4581-9c8a-8a528ab0b728",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59dd4ff-329e-4a7b-96b9-44d99e987ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.73900</td>\n",
       "      <td>0.565</td>\n",
       "      <td>260467.0</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-9.309</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>75.537</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.433</td>\n",
       "      <td>262867.0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-3.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.358</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.359</td>\n",
       "      <td>563893.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-8.323</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>89.259</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.626</td>\n",
       "      <td>-6.564</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>112.704</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.343</td>\n",
       "      <td>-11.866</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>95.000</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy   \n",
       "1        31.0       0.73900         0.565     260467.0   0.393  \\\n",
       "2        57.0       0.00879         0.433     262867.0   0.815   \n",
       "3        63.0       0.01050         0.359     563893.0   0.762   \n",
       "5        65.0           NaN         0.491         -1.0     NaN   \n",
       "6        44.0       0.71000         0.627          NaN   0.496   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness    tempo  valence  genre  \n",
       "1          0.000845     0.143    -9.309       0.0244   75.537   0.2290      0  \n",
       "2          0.000000     0.138    -3.658          NaN  125.358   0.4610      1  \n",
       "3          0.281000     0.368    -8.323       0.0320   89.259   0.1670      1  \n",
       "5          0.000003     0.626    -6.564       0.0281  112.704   0.4070      1  \n",
       "6               NaN     0.343   -11.866       0.0396   95.000   0.0801      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e640deb3-75ed-419d-a63d-6ffa398a3e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e4b0c-d771-4ef5-b6d4-fe8af6e81c76",
   "metadata": {},
   "source": [
    "- Import `SimpleImputer` and `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac1c4a2-3367-411a-8574-75e93e517594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1528cd3-e810-44f1-91cb-72f9080bff77",
   "metadata": {},
   "source": [
    "- Instantiate an `imputer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dfd83e2-d767-4c16-85b7-2bf358ea1780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e34b7-2907-48c6-a4f1-e84401c35d08",
   "metadata": {},
   "source": [
    "- Instantiate a KNN classifier with `3` neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8396bd9-37bb-4080-b4d6-643b04ad8cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8c8e5-ddb4-4cbe-ad7e-8366c8df10e6",
   "metadata": {},
   "source": [
    "- Create `steps`, a list of tuples containing the `imputer` variable you created, called `\"imputer\"`, followed by the `knn` model you created, called `\"knn\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff777596-9df5-400d-96ff-d8f9f3a5ad69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = [(\"imputer\", imputer),\n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f8c4c-8d8c-40f0-ad18-577c79ea5f68",
   "metadata": {},
   "source": [
    "### 2.3. Pipeline for song genre prediction: II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f14198-60dd-46d7-8634-01f161f44775",
   "metadata": {},
   "source": [
    "Having **set up the steps of the pipeline** in the previous exercise, you will now **use it on the `music_df` dataset to classify the genre of songs**. What makes pipelines so incredibly useful is the simple interface that they provide.\n",
    "\n",
    "`X_train`, `X_test`, `y_train`, and `y_test` have been preloaded for you, and `confusion_matrix` has been imported from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f36305-0c23-446a-8c45-6db95979e56a",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e250414-e95f-408e-a70e-f97be50e7806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"./helpers/pickle_objs.py\"\n",
    "pickled_objs = load(\"./assets/ch04_02_03_pipeline_for_song_genre_prediction_02_pickled01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18a0f84f-92da-4851-be60-d766cffa4d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test = pickled_objs[\"X_train\"], pickled_objs[\"X_test\"]\n",
    "y_train, y_test = pickled_objs[\"y_train\"], pickled_objs[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76cbbdf6-21f7-4197-8d03-a48e46e749f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb317a88-528d-42b4-b0f8-e576da57551d",
   "metadata": {},
   "source": [
    "- Create a `pipeline` using the `steps` you previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c04a63e-8562-44ed-8557-5da05f15de2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d7310-a3ff-4d62-888b-a530c263fda3",
   "metadata": {},
   "source": [
    "- Fit the `pipeline` to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38cb1d56-400f-4a79-895c-2873f9e984a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef50ca-24cd-4cf9-a885-071c56aacfb8",
   "metadata": {},
   "source": [
    "- Make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "749b7430-0f44-4576-abb9-133201f2b0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd0266-be2a-475b-807e-552262758630",
   "metadata": {},
   "source": [
    "- Calculate and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4acd8c78-dd6d-4341-bce6-a8b5298beec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79  9]\n",
      " [ 4 82]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63292b9-e6cf-4680-89ca-fbb56acd4943",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6a2ef-fa2c-4471-8839-35816bec9410",
   "metadata": {},
   "source": [
    "**Centering and scaling**\n",
    "> - Data **imputation is one of several important preprocessing steps** for machine learning.\n",
    "> - Now let's cover another: **centering and scaling our data**.\n",
    "\n",
    "**Why scale our data?**\n",
    "> - Let's **use** `music_df.describe()` to **check out the ranges** of some of our feature variables in the music dataset.\n",
    "> - We see that the **ranges vary widely**: `duration_ms` ranges from `0` to `1.62` million, `speechiness` contains only decimal places, and `loudness` only has negative values!\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img01.png\">\n",
    "\n",
    "**Why scale our data?**\n",
    "> - Many machine learning models **use some form of distance** to inform them, so **if we have features on far larger scales, they can disproportionately influence our model**.\n",
    "> - For example, **KNN uses distance explicitly** when making predictions.\n",
    "> - For this reason, we actually want features to be **on a similar scale**.\n",
    "> - To achieve this, we can **normalize** or **standardize** our data, often referred to as **scaling** and **centering**.\n",
    "\n",
    "**How to scale our data**\n",
    "> - There are **several ways** to scale our data:\n",
    ">> - Given any column, we can **subtract the mean and divide by the variance** so that **all features are centered around zero and have a variance of one**, this is called **standardization**,\n",
    ">> - We can also **subtract the minimum and divide by the range** of the data so the **normalized dataset has minimum zero and maximum one**,\n",
    ">> - Or, we can **center our data so that it ranges from -1 to 1 instead**.\n",
    "> - In this video, we will perform **standardization**, but scikit-learn has functions available for other types of scaling.\n",
    "\n",
    "**Scaling in scikit-learn**\n",
    "> - To scale our features, we **import** `StandardScaler` from `sklearn.preprocessing`.\n",
    "> - We **create** our feature and target arrays.\n",
    "> - Before scaling, we **split** our data to avoid data leakage.\n",
    "> - We then **instantiate** a `StandardScaler()` object, and **call** its `.fit_transform method()`, **passing** our training features.\n",
    "> - Next, we **use** `scaler.transform()` on the test features.\n",
    "> - Looking at the **mean** and **standard deviation** of the columns of both the original and scaled data verifies the **change has taken place**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img02.png\">\n",
    "\n",
    "**Scaling in a pipeline**\n",
    "> - We can also **put a scaler in a pipeline!**\n",
    "> - Here we **build** a pipeline object to scale our data and use a KNN model with `6` neighbors.\n",
    "> - We then **split** our data, **fit** the pipeline to our training set, and **predict** on our test set.\n",
    "> - **Computing** the accuracy yields a result of `0.81`.\n",
    "> - Let's compare this to using **unscaled data**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img03.png\">\n",
    "\n",
    "**Comparing performance using unscaled data**\n",
    "> - Here we **fit** a KNN model to our unscaled training data and **print** the accuracy.\n",
    "> - It is only `0.53`, so **just by scaling our data we improved accuracy by over 50%!**\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img04.png\">\n",
    "\n",
    "**CV and scaling in a pipeline**\n",
    "> - Let's also look at **how we can use cross-validation with a pipeline**:\n",
    ">> - We first **build** our pipeline,\n",
    ">> - We then **specify** our hyperparameter space by creating a dictionary: **the keys** are the pipeline step name followed by a double underscore, followed by the hyperparameter name**,\n",
    ">> - The **corresponding value** is a list or an array of the values to try for that particular hyperparameter,\n",
    ">> - In this case, we are **tuning** `n_neighbors` in the KNN model,\n",
    ">> - Next we **split** our data into training and test sets,\n",
    ">> - We then **perform** a grid search over our parameters by **instantiating** the `GridSearchCV()` object, **passing** our pipeline and setting the `param_grid` argument equal to `parameters`.\n",
    ">> - We then **fit** it to our training data,\n",
    ">> - Lastly, we **make predictions** using our test set.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img05.png\">\n",
    "\n",
    "**Checking model parameters**\n",
    "> - **Printing** `GridSearchCV`'s `best_score_` attribute, we see the **score is very slightly better than our previous model's performance**.\n",
    "> - **Printing** the best parameters, the optimal model has 12 neighbors.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb33cf-7153-4b24-9ca8-cc3f0749e923",
   "metadata": {},
   "source": [
    "### 3.1. Centering and scaling for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c0eb6-7364-451e-b2c2-4474cacb892c",
   "metadata": {},
   "source": [
    "Now you have seen the benefits of scaling your data, you will **use a pipeline to preprocess the music_df features and build a lasso regression model to predict a song's loudness**.\n",
    "\n",
    "`X_train`, `X_test`, `y_train`, and `y_test` have been created from the `music_df` dataset, where the target is `\"loudness\"` and the features are all other columns in the dataset. `Lasso` and `Pipeline` have also been imported for you.\n",
    "\n",
    "Note that `\"genre\"` has been converted to a binary feature where `1` indicates a rock song, and `0` represents other genres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96017b9f-ef4b-491e-a7e1-ca34b3df5029",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b33b07a5-a56e-40b3-b526-e19f163767b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"./helpers/pickle_objs.py\"\n",
    "pickled_objs = load(\"./assets/ch04_03_01_centering_and_scaling_for_regression_pickled0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de5e3866-a0b0-4c90-8a53-c19b645691c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test = pickled_objs[\"X_train\"], pickled_objs[\"X_test\"]\n",
    "y_train, y_test = pickled_objs[\"y_train\"], pickled_objs[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5df3439f-a7ef-4b67-8277-ff1da780604c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2b6d3-df8b-4857-b37c-396a86068f62",
   "metadata": {},
   "source": [
    "- Import `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d1378ff-7082-4de7-ba24-2307b2a9698b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a14fa3-c424-4af4-be0a-647db58bfac8",
   "metadata": {},
   "source": [
    "- Create the `steps` for the `pipeline` object, a `StandardScaler()` object called `\"scaler\"`, and a `lasso` model called `\"lasso\"` with `alpha` set to` 0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "554d3fc4-5a18-4869-8e34-fbcac2458128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582e5a6-b049-4ce5-a2d4-bad462808c50",
   "metadata": {},
   "source": [
    "- Instantiate a `pipeline` with `steps` to scale and build a `lasso` regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a977d857-8f5a-4679-be67-a16c9660af9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1952f26-8863-49f2-9b38-3af1be78405c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c549e18-af56-4328-984a-4d38ff44dc27",
   "metadata": {},
   "source": [
    "- Calculate the R-squared value on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a3f610b-af11-4da5-a58d-561a359dc3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193523316282489"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604135c7-18c6-40d2-877a-265773eb2ac0",
   "metadata": {},
   "source": [
    "### 3.2. Centering and scaling for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee6cb0-f6af-45ed-af53-6bfecf45bbb5",
   "metadata": {},
   "source": [
    "Now you will **bring together scaling and model building into a pipeline for cross-validation**.\n",
    "\n",
    "Your task is to build a `pipeline` to scale features in the `music_df` dataset and perform grid search cross-validation using a logistic regression model with different values for the hyperparameter `C`. The target variable here is `\"genre\"`, which contains binary values for rock as `1` and any other genre as `0`.\n",
    "\n",
    "`StandardScaler`, `LogisticRegression`, and `GridSearchCV` have all been imported for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6de768-72fb-4877-a26f-26534e161f13",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51880743-a561-4af0-8ee0-fbd96e6c3a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e127bd7-85d0-45dd-87ba-ed771bcbb60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"./helpers/pickle_objs.py\"\n",
    "pickled_objs = load(\"./assets/ch04_03_02_centering_and_scaling_for_classification_pickled01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d2fa186-c591-46b0-b73d-c74d076a1918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = pickled_objs[\"X\"], pickled_objs[\"y\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449362d8-e688-468f-9e0f-92519139d9f5",
   "metadata": {},
   "source": [
    "- Build the `steps` for the `pipeline`: a `StandardScaler()` object named `\"scaler\"`, and a logistic regression model named `\"logreg\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99a9b61d-2710-4832-98fa-20ecfcf111a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7aff7298-0088-4bd9-9b43-95ef9597d4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa756d-f4ab-4cf3-9e32-c1672df6844b",
   "metadata": {},
   "source": [
    "- Create the parameters, searching `20` equally spaced `float` values ranging from` 0.001` to `1.0` for the logistic regression model's `C `hyperparameter within the `pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d972454-50ac-4edd-b133-b2d2d5528746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5338b3-4ae6-44b2-98d0-84b76e308627",
   "metadata": {},
   "source": [
    "- Instantiate the grid search object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bedcaec7-74d2-4090-a2fb-4b9ca79914d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557d4c1-7166-40ae-8b91-38fe82de8fe3",
   "metadata": {},
   "source": [
    "- Fit the grid search object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da3d0073-e45a-4b53-be3a-06a82f86e0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfb07677-8a97-4bf8-a817-5cd5a7b8a8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8425\n",
      "{'logreg__C': 0.1061578947368421}\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_score_)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc0934-cd5f-45a0-9f51-64b582ba7321",
   "metadata": {},
   "source": [
    "## 4. Evaluating multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40021a5-79ad-4a3a-ad7b-335f67b66f58",
   "metadata": {},
   "source": [
    "**Evaluating multiple models**\n",
    "> - We've covered all parts of the **supervised learning workflow**.\n",
    "> - But how do we decide **which model to use in the first place?**\n",
    "\n",
    "**Different models for different problems**\n",
    "> - This is a **complex question**, and the **answer depends on our situation**.\n",
    "> - However, there are **some principles** that can guide us when making this decision:\n",
    ">> - The **size of our dataset** plays a role:\n",
    ">>> - **Fewer features** means a **simpler model**, and can reduce training time,\n",
    ">>> - Also, **some models**, such as Artificial Neural Networks, **require a lot of data to perform well**.\n",
    ">> - We may need an **interpretable model**, so we can explain to stakeholders **how predictions were made**:\n",
    ">>> - An example is **linear regression**, where we can **calculate and interpret the model coefficients**.\n",
    ">> - Alternatively, **flexibility** might be important to **get the most accurate predictions**:\n",
    ">>> - Generally, **flexible models make fewer assumptions about the data**; for example, a **KNN model does not assume a linear relationship between the features and the target**.\n",
    "\n",
    "**It's all in the metrics**\n",
    "> - Notice that **scikit-learn allows the same methods to be used for most models**, this makes it **easy to compare them!**\n",
    ">> - **Regression models** can be evaluated using the **root mean squared error**, or the **R-squared** value,\n",
    ">> - Likewise, **classification models** can all be analyzed using **accuracy**, **confusion matrix** and its **associated metrics**, or the **ROC AUC**.\n",
    "> - Therefore, one approach is to **select** several **model**s and a **metric(s)**, then **evaluate** their performance without any form of **hyperparameter tuning**.\n",
    "\n",
    "**A note on scaling**\n",
    "> - Recall that the performance of some models**, such as **KNN**, **linear regression**, and **logistic regression**, are **affected by scaling our data**.\n",
    "> - Therefore, it is generally best to **scale our data before evaluating models** out of the box.\n",
    "\n",
    "**Evaluating classification models**\n",
    "> - We will evaluate **three models for binary classification** of song genre: **KNN**, *logistic regression**, and a new model called a **decision tree classifier**.\n",
    "> - We **import** our required modules, including `DecisionTreeClassifier` from `sklearn.tree`, the workings of decision trees are outside the scope of this course, but the steps for building this model are the same as for other models in scikit-learn.\n",
    "> - As usual, we **create** our feature and target arrays, then **split** our data.\n",
    "> - We then **scale** our features using the scaler's **`.fit_transform()` method on the training set, and the `.transform()` method on the test set**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_04_evaluating_multiple_models_img01.png\">\n",
    "\n",
    "**Evaluating classification models**\n",
    "> - We **create** a dictionary with our model names as strings for the keys, and **instantiate** models as the dictionary's values.\n",
    "> - We also **create** an empty list to store the results.\n",
    "> - Now we **loop through** the models in our models dictionary, using its `.values()` method.\n",
    "> - Inside the loop, we **instantiate** a `KFold()` object.\n",
    "> - Next we **perform** cross-validation, using the model being iterated, along with our scaled training features, and target training array.\n",
    "> - We **set** `cv` equal to our `kfold` variable.\n",
    "> - By default, the scoring here will be **accuracy**.\n",
    "> - We then **append** the cross-validation results to our results list.\n",
    "> - Lastly, outside of the loop, we **create** a boxplot of our results, and **set** the labels argument equal to a call of model's `.keys()` to retrieve each model's name.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_04_evaluating_multiple_models_img02.png\">\n",
    "\n",
    "**Visualizing results**\n",
    "> - The output shows us the **range of cross-validation accuracy scores**.\n",
    "> - We can also see **each model's median cross-validation score**, represented by the **orange line** in each box.\n",
    "> - We can see **logistic regression has the best median score**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_04_evaluating_multiple_models_img03.png\">\n",
    "\n",
    "**Test set performance**\n",
    "> - To evaluate on the test set we **loop through** the names and values of the dictionary using the `.items()` method.\n",
    "> - Inside the loop we **fit** the model, **calculate** accuracy, and print it.\n",
    "> - **Logistic regression performs best** for this problem if we are using **accuracy** as the metric.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_04_evaluating_multiple_models_img04.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745000c-d765-48bc-88f3-aa675f0cfbb7",
   "metadata": {},
   "source": [
    "### 4.1. Visualizing regression model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0398cf-a659-4279-ba65-931217e873a1",
   "metadata": {},
   "source": [
    "Now you have seen how to **evaluate multiple models out of the box**, you will build three regression models to predict a song's `\"energy\"` levels.\n",
    "\n",
    "The `music_df` dataset has had dummy variables for `\"genre\"` added. Also, feature and target arrays have been created, and these have been split into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "The following have been imported for you: `LinearRegression`, `Ridge`, `Lasso`, `cross_val_score`, and `KFold`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4386e-662b-400e-a9ab-429ab85ccc08",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b77a7c37-76a2-48ad-80c7-b07593fce34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run \"./helpers/pickle_objs.py\"\n",
    "pickled_objs = load(\"./assets/ch04_04_01_visualizing_regression_model_performance_pickled01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4585aa85-5bdc-45af-832d-d1d7527556d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test = pickled_objs[\"X_train\"], pickled_objs[\"X_test\"]\n",
    "y_train, y_test = pickled_objs[\"y_train\"], pickled_objs[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "052b13da-0f41-40cc-b6ef-aaa8508199ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f5581-bcce-4333-a866-60b77971b7cd",
   "metadata": {},
   "source": [
    "- Write a `for` loop using `model` as the iterator, and `model.values()` as the iterable.\n",
    "- Perform cross-validation on the training features and the training target array using the model, setting `cv` equal to the `KFold` object.\n",
    "- Append the model's cross-validation scores to the `results` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e88f6a82-b30c-4be4-9cca-d786a34e5c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(),\n",
    "          \"Ridge\": Ridge(alpha=0.1),\n",
    "          \"Lasso\": Lasso(alpha=0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60cf0cee-e0a4-4a9d-8f89-12616e35682b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=6, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5774c4e2-8b12-4a8e-af97-d8d67a3d9073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in models.values():\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    results.append(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ce835-e0e2-406a-8372-926e4bb800a3",
   "metadata": {},
   "source": [
    "- Create a box plot displaying the results, with the x-axis labels as the names of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3124d9a-2eae-4d99-ac2e-545e05ef131c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(x=results, labels=models.keys());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcc0e3-2efb-4d93-b6f6-e7b5acc194ce",
   "metadata": {},
   "source": [
    "### 4.2. Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a675c-4a7a-442e-8216-36e80fd65666",
   "metadata": {},
   "source": [
    "In the last exercise, linear regression and ridge appeared to produce similar results. It would be appropriate to select either of those models; however, you can **check predictive performance on the test set to see if either one can outperform the other**.\n",
    "\n",
    "You will use root mean squared error (RMSE) as the metric. The dictionary `models`, containing the names and instances of the two models, has been preloaded for you along with the training and target arrays `X_train_scaled`, `X_test_scaled`, `y_train`, and `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e349d0-2eae-4b9e-9c6a-67383d1ca396",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce088f21-e68d-4b6e-a6c4-a4710721f19f",
   "metadata": {},
   "source": [
    "- Import `mean_squared_error`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b346a-199f-44b0-a9db-db598f4f9433",
   "metadata": {},
   "source": [
    "- Fit the model to the scaled training features and the training labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76aac46-ae23-426c-8f1d-bd7e90da1d82",
   "metadata": {},
   "source": [
    "- Make predictions using the scaled test features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f54b4-af44-4c68-997a-5c095f9edb8d",
   "metadata": {},
   "source": [
    "- Calculate RMSE by passing the test set labels and the predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329417f-4f94-4f0a-a60a-1fc7761df174",
   "metadata": {},
   "source": [
    "### 4.3. Visualizing classification model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21eecc-9e10-4e26-8c59-1eca649b5778",
   "metadata": {},
   "source": [
    "In this exercise, you will be **solving a classification problem** where the `\"popularity\"` column in the `music_df` dataset has been converted to binary values, with `1` representing popularity more than or equal to the median for the `\"popularity\"` column, and `0` indicating popularity below the median.\n",
    "\n",
    "Your task is to **build and visualize the results of three different models to classify whether a song is popular or not**.\n",
    "\n",
    "The data has been split, scaled, and preloaded for you as `X_train_scaled`, `X_test_scaled`, `y_train`, and `y_test`. Additionally, `KNeighborsClassifier`, `DecisionTreeClassifier`, and `LogisticRegression` have been imported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c06c9-6ef7-4976-a605-8c5f2682250d",
   "metadata": {},
   "source": [
    "- Set up the workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb5c6f-b850-4701-895d-506d22528695",
   "metadata": {},
   "source": [
    "- Create a dictionary of `\"Logistic Regression\"`, `\"KNN\"`, and `\"Decision Tree Classifier\"`, setting the dictionary's values to a call of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2402b8-9cc2-49a9-9d2e-d235e330ae12",
   "metadata": {},
   "source": [
    "- Loop through the values in `models`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0bfb4-82f1-4790-b4ae-679989d7f6c8",
   "metadata": {},
   "source": [
    "- Instantiate a `KFold()` object to perform `6` splits, setting `shuffle` to `True` and `random_state` to `12`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fcce3d-4821-42e5-8995-95f4bc2d758f",
   "metadata": {},
   "source": [
    "- Perform cross-validation using the model, the scaled training features, the target training set, and setting `cv` equal to `kf`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d35ef0-be3e-4b42-a61b-b7e78607562d",
   "metadata": {},
   "source": [
    "### 4.4. Pipeline for predicting song popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f284b3-feb8-4a48-ad0d-ac43ded8cdf6",
   "metadata": {},
   "source": [
    "For the final exercise, you will **build a pipeline to impute missing values, scale features, and perform hyperparameter tuning of a logistic regression model**. The aim is to find the best parameters and accuracy when predicting song genre!\n",
    "\n",
    "All the models and objects required to build the pipeline have been preloaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca089d-7ef2-4b5f-9503-dca5cdc9813a",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75daca1-db82-4dd6-978c-f98d58b4643b",
   "metadata": {},
   "source": [
    "- Create the `steps` for the `pipeline` by calling a simple imputer, a standard scaler, and a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f0af67-1ccd-4fb8-8f33-74d8ebdb44a5",
   "metadata": {},
   "source": [
    "- Create a pipeline object, and pass the `steps` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f1abb-a85c-4ef8-af56-10e19a1ed769",
   "metadata": {},
   "source": [
    "- Instantiate a grid search object to perform cross-validation using the pipeline and the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442b7c6-4f8f-475f-ba87-9c468e59298e",
   "metadata": {},
   "source": [
    "- Print the best parameters and compute and print the test set accuracy score for the grid search object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89754cb-1ee3-48c8-aa66-1b6c23ae0b89",
   "metadata": {},
   "source": [
    "## 5. Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc60be1-24a2-4865-b8ec-419397e0d9a4",
   "metadata": {},
   "source": [
    "**What you've covered**\n",
    "> - To **recap** you have learned:\n",
    ">> - The fundamentals of using **supervised learning techniques** to build predictive models for both **regressio**n and **classification** problems,\n",
    ">> - You have learned the concepts of **underfitting** and **overfitting**, how to **split** data, and perform **cross-validation**,\n",
    ">> - You also learned about **data preprocessing** techniques, **selected which model to build**, performed **hyperparameter tuning**, assessed **model performance**, and used **pipelines**!\n",
    "\n",
    "**Where to go from here?**\n",
    "> - We covered several models, **but there are plenty of others**, so to learn more we recommend checking out **some of our courses**.\n",
    "> - We also have **courses that dive deeper into topics we introduced**, such as:\n",
    ">> - Machine Learning with Tree-Based Models in Python,\n",
    ">> - Preprocessing for Machine Learning in Python,\n",
    ">> - Model Validation in Python.\n",
    "> - There are other **courses on topics we did not cover**, such as:\n",
    ">> - Feature Engineering for Machine Learning in Python,\n",
    ">> - Unsupervised Learning in Python.\n",
    "feature engineering, and unsupervised learning.\n",
    "> - Additionally, we have many **machine learning projects** where you can apply the skills you've learned here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc50322-c2f7-45d3-be7b-18ca71d84aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data-Science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
