{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83930df-8652-4cfe-84b9-1145b082453d",
   "metadata": {},
   "source": [
    "# Chapter #4: Preprocessing and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7872ce3-6c74-4384-a0f7-0df4d3163e3e",
   "metadata": {},
   "source": [
    "## 1. Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a70f9-547b-410b-b17d-d78bec26a5a2",
   "metadata": {},
   "source": [
    "**scikit-learn requirements**\n",
    "> - Recall that **scikit-learn requires numeric data, with no missing values**.\n",
    "> - All the data that we have used so far has been in this format.\n",
    "> - However, with **real-world data**, this will rarely be the case, and instead **we need to preprocess our data before we can build models**.\n",
    "\n",
    "**Dealing with categorical features**\n",
    "> - Say we have a dataset containing **categorical features**, such as color.\n",
    "> - As these are not numeric, **scikit-learn will not accept them** and we need to convert them into **numeric features**.\n",
    "> - We achieve this by **splitting the feature into multiple binary features called dummy variables**, one for each category.\n",
    "> - **`0`** means the observation was **not that category**, while **`1`** means **it was**.\n",
    "\n",
    "**Dummy variables**\n",
    "> - Say we are working with a music dataset that has a genre feature with 10 values such as Electronic, Hip-Hop, and Rock.\n",
    "> - We create **binary features** for each genre.\n",
    "> - As each song has one genre, **each row will have a `1` in one of the 10 columns** and `0` in the rest.\n",
    "> - If a song is not any of the first nine genres, **then implicitly, it is a rock song**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img01.png\">\n",
    "\n",
    "**Dummy variables**\n",
    "> - That means **we only need nine features, so we can delete the Rock column**.\n",
    "> - If we do not do this, **we are duplicating information, which might be an issue for some models**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img02.png\">\n",
    "\n",
    "**Dealing with categorical features in Python**\n",
    "> - To create **dummy variables** we can use:\n",
    ">> - **scikit-learn's** `OneHotEncoder()`,\n",
    ">> - **pandas'** `get_dummies()`.\n",
    "> - We will use **`get_dummies()`**.\n",
    "\n",
    "**Music dataset**\n",
    "> - We will be working with a **music dataset** in this chapter, for both **classification** and **regression** problems.\n",
    "> - Initially, we will build a **regression model** using all features in the dataset to **predict song `popularity`**.\n",
    "> - There is one categorical feature, **`genre`**, with **ten possible values**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img03.png\">\n",
    "\n",
    "**EDA w/ categorical feature**\n",
    "> - This box plot shows how **`popularity` varies by `genre`**.\n",
    "> - Let's encode this feature using **dummy variables**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img04.png\">\n",
    "\n",
    "**Encoding dummy variables**\n",
    "> - We **import** pandas, **read** in the DataFrame, and **call** `pd.get_dummies()`, **passing** the categorical column.\n",
    "> - As we only need to keep 9 out of our 10 binary features, we can **set** the `drop_first` argument to `True`.\n",
    "> - Printing the first five rows, we see **pandas creates 9 new binary features**.\n",
    "> - The first song is Jazz, and the second is Rap, indicated by a `1` in the respective columns.\n",
    "> - To bring these binary features back into our original DataFrame we can **use** `pd.concat()`, **passing** a list containing the `music_df` DataFrame and our `music_dummies` DataFrame, and setting `axis` equal to `1`.\n",
    "> - Lastly, we can **remove** the original `genre` column using `.drop()`, **passing(()) the column, and setting `axis` equal to `1`.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img05.png\">\n",
    "\n",
    "**Encoding dummy variables**\n",
    "> - If the DataFrame only has one categorical feature, we can **pass** the entire DataFrame, thus skipping the step of combining variables.\n",
    "> - If we **don't specify a column**, the new DataFrame's binary columns will have the original feature name **prefixed**, so they will start with genre-underscore - as shown here.\n",
    "> - Notice the original genre column is **automatically dropped**.\n",
    "> - Once we have dummy variables, we can **fit** models as before.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img07.png\">\n",
    "\n",
    "**Linear regression with dummy variables**\n",
    "> - Using the `music_dummies` DataFrame, the process for creating **training** and **test sets** remains unchanged.\n",
    "> - To perform **cross-validation** we then **create** a `KFold()` object, **instantiate** a linear regression model, and **call** `cross_val_score()`.\n",
    "> - We **set** scoring equal to `neg_mean_squared_error`, which **returns the negative MSE**.\n",
    "> - This is because scikit-learn's cross-validation metrics presume a **higher score is better**, so **MSE** is changed to **negative MSE** to counteract this.\n",
    "> - We can **calculate** the training RMSE by **taking the square root and converting to positive**, achieved by **calling** `numpy.square-root()` and **passing** our scores with a **minus sign** in front.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_01_preprocessing_data_img08.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d79409-bdc0-48f8-8375-67365a10e340",
   "metadata": {},
   "source": [
    "### 1.1. Creating dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68d607-f9bc-4ea1-82c1-53162cc60941",
   "metadata": {},
   "source": [
    "Being able to **include categorical features in the model building process** can enhance performance as they may add information that contributes to prediction accuracy.\n",
    "\n",
    "The `music_df` dataset has been preloaded for you, and its shape is printed. Also, `pandas` has been imported as `pd`.\n",
    "\n",
    "Now you will create a new DataFrame containing the original columns of `music_df` plus dummy variables from the `\"genre\"` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d21d33-105f-48fb-8c21-9367e3f29978",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c387215-ef24-4c95-92aa-1777bf12f6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.823</td>\n",
       "      <td>236533.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>102.619000</td>\n",
       "      <td>0.649</td>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154373.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>173.915000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.669</td>\n",
       "      <td>217778.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.522</td>\n",
       "      <td>245960.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.595</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229400.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>96.056000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0        41.0        0.6440         0.823     236533.0   0.814   \n",
       "1        62.0        0.0855         0.686     154373.0   0.670   \n",
       "2        42.0        0.2390         0.669     217778.0   0.736   \n",
       "3        64.0        0.0125         0.522     245960.0   0.923   \n",
       "4        60.0        0.1210         0.780     229400.0   0.467   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence  \\\n",
       "0          0.687000    0.1170    -5.611       0.1770  102.619000    0.649   \n",
       "1          0.000000    0.1200    -7.626       0.2250  173.915000    0.636   \n",
       "2          0.000169    0.5980    -3.223       0.0602  145.061000    0.494   \n",
       "3          0.017000    0.0854    -4.560       0.0539  120.406497    0.595   \n",
       "4          0.000134    0.3140    -6.645       0.2530   96.056000    0.312   \n",
       "\n",
       "        genre  \n",
       "0        Jazz  \n",
       "1         Rap  \n",
       "2  Electronic  \n",
       "3        Rock  \n",
       "4         Rap  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv(\"./datasets/music.csv\").drop(columns=\"Unnamed: 0\")\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41263729-bfc7-4acd-b95e-62b60a5968f5",
   "metadata": {},
   "source": [
    "- Use a relevant function, passing the entire `music_df` DataFrame, to create `music_dummies`, dropping the first binary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39d3a13-042c-4378-9301-9ccb35f02c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_anime</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_hip-hop</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_rap</th>\n",
       "      <th>genre_rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.823</td>\n",
       "      <td>236533.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>102.619000</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154373.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>173.915000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.669</td>\n",
       "      <td>217778.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.522</td>\n",
       "      <td>245960.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229400.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>96.056000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0        41.0        0.6440         0.823     236533.0   0.814   \n",
       "1        62.0        0.0855         0.686     154373.0   0.670   \n",
       "2        42.0        0.2390         0.669     217778.0   0.736   \n",
       "3        64.0        0.0125         0.522     245960.0   0.923   \n",
       "4        60.0        0.1210         0.780     229400.0   0.467   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence  \\\n",
       "0          0.687000    0.1170    -5.611       0.1770  102.619000    0.649   \n",
       "1          0.000000    0.1200    -7.626       0.2250  173.915000    0.636   \n",
       "2          0.000169    0.5980    -3.223       0.0602  145.061000    0.494   \n",
       "3          0.017000    0.0854    -4.560       0.0539  120.406497    0.595   \n",
       "4          0.000134    0.3140    -6.645       0.2530   96.056000    0.312   \n",
       "\n",
       "   genre_anime  genre_blues  genre_classical  genre_country  genre_electronic  \\\n",
       "0            0            0                0              0                 0   \n",
       "1            0            0                0              0                 0   \n",
       "2            0            0                0              0                 1   \n",
       "3            0            0                0              0                 0   \n",
       "4            0            0                0              0                 0   \n",
       "\n",
       "   genre_hip-hop  genre_jazz  genre_rap  genre_rock  \n",
       "0              0           1          0           0  \n",
       "1              0           0          1           0  \n",
       "2              0           0          0           0  \n",
       "3              0           0          0           1  \n",
       "4              0           0          1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dummies = pd.get_dummies(music_df, drop_first=True).rename(columns=lambda x: x.lower())\n",
    "music_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc37b8-5083-4bd1-8e7a-2cb372561159",
   "metadata": {},
   "source": [
    "- Print the shape of `music_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21447c2b-e06a-4e36-9a16-b754e1e40a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a78d1-ff21-4deb-af56-795876ddf030",
   "metadata": {},
   "source": [
    "### 1.2. Regression with categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9f2aa-74d0-4a6f-8b55-97c9ae8b232c",
   "metadata": {},
   "source": [
    "Now you have created `music_dummies`, containing binary features for each song's genre, it's time to **build a ridge regression model to predict song popularity**.\n",
    "\n",
    "`music_dummies` has been preloaded for you, along with Ridge, `cross_val_score`, `numpy` as `np`, and a `KFold()` object stored as `kf`.\n",
    "\n",
    "The model will be evaluated by calculating the average RMSE, but first, you will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value â€”`\"popularity\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cd5e5-3d90-45d3-9447-f6156b3b6ec2",
   "metadata": {},
   "source": [
    "- Set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d2119d-253a-404d-9084-e48666fd257c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8dce75-7cb3-47f9-b37f-c9368b285bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_anime</th>\n",
       "      <th>genre_blues</th>\n",
       "      <th>genre_classical</th>\n",
       "      <th>genre_country</th>\n",
       "      <th>genre_electronic</th>\n",
       "      <th>genre_hip-hop</th>\n",
       "      <th>genre_jazz</th>\n",
       "      <th>genre_rap</th>\n",
       "      <th>genre_rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.823</td>\n",
       "      <td>236533.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-5.611</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>102.619000</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.686</td>\n",
       "      <td>154373.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>-7.626</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>173.915000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.669</td>\n",
       "      <td>217778.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>-3.223</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>145.061000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.522</td>\n",
       "      <td>245960.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>-4.560</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>120.406497</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.780</td>\n",
       "      <td>229400.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>-6.645</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>96.056000</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0        41.0        0.6440         0.823     236533.0   0.814   \n",
       "1        62.0        0.0855         0.686     154373.0   0.670   \n",
       "2        42.0        0.2390         0.669     217778.0   0.736   \n",
       "3        64.0        0.0125         0.522     245960.0   0.923   \n",
       "4        60.0        0.1210         0.780     229400.0   0.467   \n",
       "\n",
       "   instrumentalness  liveness  loudness  speechiness       tempo  valence  \\\n",
       "0          0.687000    0.1170    -5.611       0.1770  102.619000    0.649   \n",
       "1          0.000000    0.1200    -7.626       0.2250  173.915000    0.636   \n",
       "2          0.000169    0.5980    -3.223       0.0602  145.061000    0.494   \n",
       "3          0.017000    0.0854    -4.560       0.0539  120.406497    0.595   \n",
       "4          0.000134    0.3140    -6.645       0.2530   96.056000    0.312   \n",
       "\n",
       "   genre_anime  genre_blues  genre_classical  genre_country  genre_electronic  \\\n",
       "0            0            0                0              0                 0   \n",
       "1            0            0                0              0                 0   \n",
       "2            0            0                0              0                 1   \n",
       "3            0            0                0              0                 0   \n",
       "4            0            0                0              0                 0   \n",
       "\n",
       "   genre_hip-hop  genre_jazz  genre_rap  genre_rock  \n",
       "0              0           1          0           0  \n",
       "1              0           0          1           0  \n",
       "2              0           0          0           0  \n",
       "3              0           0          0           1  \n",
       "4              0           0          1           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a80084-250d-4bc4-bd3a-7a4cef7672fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac37ee-6736-4be5-b2aa-ee00cf563327",
   "metadata": {},
   "source": [
    "- Create `X`, containing all features in `music_dummies`, and `y`, consisting of the `\"popularity\"` column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7743e28a-3ce5-41df-a843-3f3bcfa47d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = music_dummies.drop(columns=\"popularity\").values\n",
    "y = music_df[\"popularity\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04879a-d739-408c-9d68-99809a80dd5a",
   "metadata": {},
   "source": [
    "- Instantiate a `ridge` regression model, setting `alpha` equal to `0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8b6dcc-15df-411a-a356-e27e5dc1f0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8f60c-fa65-4efb-8a56-633fb5dafbcb",
   "metadata": {},
   "source": [
    "- Perform cross-validation on `X` and `y` using the `ridge` model, setting `cv` equal to `kf`, and using negative mean squared error as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d3a07e-02b3-44c4-9b96-4c0e0eeffd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c016e31-baec-4b11-9489-ea3dcdecd971",
   "metadata": {},
   "source": [
    "- Print the RMSE values by converting negative `scores` to positive and taking the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c5ce5f-9a70-4e03-b594-b06b48d18af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313d62b7-6e30-47f5-811b-143bb38b1429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 8.24\n",
      "Standard deviation of the target array: 14.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average RMSE: {np.mean(rmse):.2f}\")\n",
    "print(f\"Standard deviation of the target array: {np.std(y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645d912b-4049-464b-bcb6-81457f929969",
   "metadata": {},
   "source": [
    "## 2. Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c0d8a-2c8a-4af7-8294-1de151d4ae67",
   "metadata": {},
   "source": [
    "**Missing data**\n",
    "> - When there is **no value** for a feature in a particular row, we call it **missing** data.\n",
    "> - This can happen because **there was no observation or the data might be corrupt**.\n",
    "> - Whatever the reason, **we need to deal with it**.\n",
    "\n",
    "**Music dataset**\n",
    "> - Previously we worked with a **modified** music dataset.\n",
    "> - Now let's inspect the **original*** version, which contains one thousand rows.\n",
    "> - We do this by chaining `pandas`' `.isna()` with `.sum()` and `.sort()` values.\n",
    "> - Each feature is **missing** between `8` and `200` values!\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img01.png\">\n",
    "\n",
    "**Dropping missing data**\n",
    "> - A common approach is to **remove missing observations accounting for less than 5% of all data**.\n",
    "> - To do this, we **use** `pandas`' `.dropna()` method, **passing** a list of columns with **less than 5% missing values** to the subset argument.\n",
    "> - If there are missing values in our subset column, **the entire row is removed**.\n",
    "> - Rechecking the DataFrame, we see **fewer missing values**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img02.png\">\n",
    "\n",
    "**Imputing values**\n",
    "> - Another option is to **impute missing data**.\n",
    "> - This means **making an educated guess as to what the missing values could be**:\n",
    ">> - We can impute the **mean** of all non-missing entries for a given feature,\n",
    ">> - We can also use other values like the **median**,\n",
    ">> - For **categorical** values we commonly impute the **most frequent value**.\n",
    "> - **Note we must split our data before imputing to avoid leaking test set information to our model, a concept known as data leakage.**\n",
    "\n",
    "**Imputation with scikit-learn**\n",
    "> - Here is a **workflow** for imputation to predict song popularity:\n",
    ">> - We **import** `SimpleImputer` from `sklearn.impute`,\n",
    ">> - As we will use **different imputation methods** for **categorical** and **numeric** features, we first **split** them, storing as `X_cat` and `X_num` respectively, along with our target array as `y`,\n",
    ">> - We **create** categorical training and test sets,\n",
    ">> - We **repeat** this for the numeric features,\n",
    ">> - By using the same value for the `random_state` argument, the target arrays' values remain **unchanged**,\n",
    ">> - To impute missing categorical values we **instantiate** a `SimpleImputer`, **setting** strategy as most frequent,\n",
    ">> - By default, `SimpleImputer` expects `numpy.nan` to represent **missing values**,\n",
    ">> - Now we **call** `.fit_transform()` to impute the training categorical features' missing values!\n",
    ">> - **For the test categorical features, we call `.transform()`.**\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img03.png\">\n",
    "\n",
    "**Imputation with scikit-learn**\n",
    "> - For our **numeric** data, we **instantiate** another imputer.\n",
    "> - By default, it fills values with the **mean**.\n",
    "> - **We fit and transform the training features, and transform the test features.**\n",
    "> - We then **combine** our training data using `numpy.append()`, **passing** our two arrays, and set `axis` equal to `1`.\n",
    "> - We **repeat** this for our test data.\n",
    "> - Due to their ability to **transform** our data, imputers are known as **transformers**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img04.png\">\n",
    "\n",
    "**Imputing within a pipeline**\n",
    "> - We can also impute using a **pipeline**, which is an **object used to run a series of transformations and build a model in a single workflow**.\n",
    "> - To do this, we **import** `Pipeline` from `sklearn.pipeline`.\n",
    "> - Here we perform **binary classification** to predict whether a song is rock or another genre.\n",
    "> - We **drop** missing values accounting for less than 5% of our data.\n",
    "> - We **convert** values in the genre column, which will be the target, to a `1` if Rock, else `0`, using `numpy.where()`.\n",
    "> - We then create `X` and `y`.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img05.png\">\n",
    "\n",
    "**Imputing within a pipeline**\n",
    "> - To build a pipeline we **construct** a list of steps containing **tuples with the step names specified as strings, and instantiate the transformer or model**. \n",
    "> - We **pass** this list when **instantiating** a Pipeline.\n",
    "> - We then **split** our data, and **fit** the pipeline to the training data, as with any other model.\n",
    "> - Finally, we **compute** accuracy.\n",
    "> - **Note that, in a pipeline, each step but the last must be a transformer.**\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_02_handling_missing_data_img06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63292b9-e6cf-4680-89ca-fbb56acd4943",
   "metadata": {},
   "source": [
    "## 3. Centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6a2ef-fa2c-4471-8839-35816bec9410",
   "metadata": {},
   "source": [
    "**Centering and scaling**\n",
    "> - Data **imputation is one of several important preprocessing steps** for machine learning.\n",
    "> - Now let's cover another: **centering and scaling our data**.\n",
    "\n",
    "**Why scale our data?**\n",
    "> - Let's **use** `music_df.describe()` to check out the **ranges** of some of our feature variables in the music dataset.\n",
    "> - We see that the **ranges vary widely**: `duration_ms` ranges from `0` to `1.62` million, `speechiness` contains only decimal places, and `loudness` only has negative values!\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img01.png\">\n",
    "\n",
    "**Why scale our data?**\n",
    "> - Many machine learning models use **some form of distance** to inform them, so **if we have features on far larger scales, they can disproportionately influence our model**.\n",
    "> - For example, **KNN uses distance explicitly** when making predictions.\n",
    "> - For this reason, we actually want features to be **on a similar scale**.\n",
    "> - To achieve this, we can **normalize** or **standardize** our data, often referred to as **scaling** and **centering**.\n",
    "\n",
    "**How to scale our data**\n",
    "> - There are **several ways** to scale our data:\n",
    ">> - Given any column, we can **subtract the mean and divide by the variance** so that **all features are centered around zero and have a variance of one**, this is called **standardization**,\n",
    ">> - We can also **subtract the minimum and divide by the range** of the data so the **normalized dataset has minimum zero and maximum one**,\n",
    ">> - Or, we can **center our data so that it ranges from -1 to 1 instead**.\n",
    "> - In this video, we will perform **standardization**, but scikit-learn has functions available for other types of scaling.\n",
    "\n",
    "**Scaling in scikit-learn**\n",
    "> - To scale our features, we **import** `StandardScaler` from `sklearn.preprocessing`.\n",
    "> - We **create** our feature and target arrays.\n",
    "> - Before scaling, we **split** our data to avoid data leakage.\n",
    "> - We then **instantiate** a `StandardScaler()` object, and **call** its `.fit_transform method()`, **passing** our training features.\n",
    "> - Next, we **use** `scaler.transform()` on the test features.\n",
    "> - Looking at the **mean** and **standard deviation** of the columns of both the original and scaled data verifies the **change has taken place**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img02.png\">\n",
    "\n",
    "**Scaling in a pipeline**\n",
    "> - We can also **put a scaler in a pipeline!**\n",
    "> - Here we **build** a pipeline object to scale our data and use a KNN model with `6` neighbors.\n",
    "> - We then **split** our data, **fit** the pipeline to our training set, and **predict** on our test set.\n",
    "> - **Computing** the accuracy yields a result of `0.81`.\n",
    "> - Let's compare this to using **unscaled data**.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img03.png\">\n",
    "\n",
    "**Comparing performance using unscaled data**\n",
    "> - Here we **fit** a KNN model to our unscaled training data and **print** the accuracy.\n",
    "> - It is only `0.53`, so **just by scaling our data we improved accuracy by over 50%!**\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img04.png\">\n",
    "\n",
    "**CV and scaling in a pipeline**\n",
    "> - Let's also look at **how we can use cross-validation with a pipeline**:\n",
    ">> - We first **build** our pipeline,\n",
    ">> - We then **specify** our hyperparameter space by creating a dictionary: **the keys** are the pipeline step name followed by a double underscore, followed by the hyperparameter name**,\n",
    ">> - The **corresponding value** is a list or an array of the values to try for that particular hyperparameter,\n",
    ">> - In this case, we are **tuning** `n_neighbors` in the KNN model,\n",
    ">> - Next we **split** our data into training and test sets,\n",
    ">> - We then **perform** a grid search over our parameters by **instantiating** the `GridSearchCV()` object, **passing** our pipeline and setting the `param_grid` argument equal to `parameters`.\n",
    ">> - We then **fit** it to our training data,\n",
    ">> - Lastly, we **make predictions** using our test set.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img05.png\">\n",
    "\n",
    "**Checking model parameters**\n",
    "> - **Printing** `GridSearchCV`'s `best_score_` attribute, we see the **score is very slightly better than our previous model's performance**.\n",
    "> - **Printing** the best parameters, the optimal model has 12 neighbors.\n",
    "\n",
    "<img style=\"margin-left: auto; margin-right: auto;\" src=\"./assets/ch04_03_centering_and scaling_img06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc0934-cd5f-45a0-9f51-64b582ba7321",
   "metadata": {},
   "source": [
    "## 4. Evaluating multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89754cb-1ee3-48c8-aa66-1b6c23ae0b89",
   "metadata": {},
   "source": [
    "## 5. Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc60be1-24a2-4865-b8ec-419397e0d9a4",
   "metadata": {},
   "source": [
    "**What you've covered**\n",
    "> - To **recap** you have learned:\n",
    ">> - The fundamentals of using **supervised learning techniques** to build predictive models for both **regressio**n and **classification** problems,\n",
    ">> - You have learned the concepts of **underfitting** and **overfitting**, how to **split** data, and perform **cross-validation**,\n",
    ">> - You also learned about **data preprocessing** techniques, **selected which model to build**, performed **hyperparameter tuning**, assessed **model performance**, and used **pipelines**!\n",
    "\n",
    "**Where to go from here?**\n",
    "> - We covered several models, **but there are plenty of others**, so to learn more we recommend checking out **some of our courses**.\n",
    "> - We also have **courses that dive deeper into topics we introduced**, such as:\n",
    ">> - Machine Learning with Tree-Based Models in Python,\n",
    ">> - Preprocessing for Machine Learning in Python,\n",
    ">> - Model Validation in Python.\n",
    "> - There are other **courses on topics we did not cover**, such as:\n",
    ">> - Feature Engineering for Machine Learning in Python,\n",
    ">> - Unsupervised Learning in Python.\n",
    "feature engineering, and unsupervised learning.\n",
    "> - Additionally, we have many **machine learning projects** where you can apply the skills you've learned here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc50322-c2f7-45d3-be7b-18ca71d84aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data-Science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
